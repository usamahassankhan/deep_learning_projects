{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "(404, 13)\n",
    "test_data.shape\n",
    "(102, 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)#In Pandas: axis=0 means along \"indexes\". It's a row-wise operatio\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# For Reusability, model is defined as a function.\n",
    "\n",
    "def build_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(64, activation = 'relu', input_shape = (train_data.shape[1],))) # number of features (13) are used as vector in input shape\n",
    "  model.add(layers.Dense(64, activation = 'relu'))\n",
    "  model.add(layers.Dense(1)) # no activation function\n",
    "  model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  0\n",
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 2s 7ms/sample - loss: 219.1878 - mae: 10.6380\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 29.1478 - mae: 3.6328\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 21.9141 - mae: 3.0716\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 18.7416 - mae: 2.8165\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 16.2962 - mae: 2.6758\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 15.1864 - mae: 2.5359\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 14.0303 - mae: 2.53880s - lo\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 13.7792 - mae: 2.3998\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 13.2879 - mae: 2.3974\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.7673 - mae: 2.3377\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 12.7628 - mae: 2.3023\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.9288 - mae: 2.2856\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.9786 - mae: 2.1844\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.2545 - mae: 2.1731\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.4523 - mae: 2.1910\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.6254 - mae: 2.1973\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.1663 - mae: 2.2074\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.4048 - mae: 2.1058\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.4095 - mae: 2.0881\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.9899 - mae: 2.0736\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.3000 - mae: 2.1146\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.8421 - mae: 2.0717\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.8538 - mae: 2.0965\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.6035 - mae: 2.0801\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.3686 - mae: 2.0058\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 9.3603 - mae: 2.0373 0s - loss: 6.089\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.8892 - mae: 2.0763\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 8.9312 - mae: 1.9508\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 9.1604 - mae: 2.0370\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.9615 - mae: 2.0046\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 8.3377 - mae: 1.9909\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.7339 - mae: 1.9121\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.5791 - mae: 1.9455\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.3952 - mae: 1.9277\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.4827 - mae: 1.9471\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.2638 - mae: 1.9284\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8648 - mae: 1.8804\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.4621 - mae: 1.8385\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.4798 - mae: 1.8843\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2077 - mae: 1.8332\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8991 - mae: 1.8107\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.4395 - mae: 1.8269\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2123 - mae: 1.8389\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 7.0585 - mae: 1.7942\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2149 - mae: 1.8442\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.1043 - mae: 1.7857\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.6088 - mae: 1.7847\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 7.4445 - mae: 1.8369\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 6.9525 - mae: 1.7311\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.0713 - mae: 1.7799\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.7262 - mae: 1.7047\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.0278 - mae: 1.7792\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.8812 - mae: 1.7221\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4837 - mae: 1.6765\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4401 - mae: 1.7418\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.2047 - mae: 1.7475\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4063 - mae: 1.6983\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - ETA: 0s - loss: 5.8936 - mae: 1.621 - 1s 2ms/sample - loss: 5.9928 - mae: 1.6517\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.3018 - mae: 1.6738\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4697 - mae: 1.6399\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8493 - mae: 1.6324\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4254 - mae: 1.6721\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 6.0083 - mae: 1.6504\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.0605 - mae: 1.6634\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.9062 - mae: 1.6240\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.1163 - mae: 1.6548\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6846 - mae: 1.6220\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6846 - mae: 1.6187\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.0824 - mae: 1.5778\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4418 - mae: 1.5157\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6243 - mae: 1.5791\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.5166 - mae: 1.5757\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3155 - mae: 1.5593\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.5465 - mae: 1.5953\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.2807 - mae: 1.5922\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2442 - mae: 1.5262\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 4.9965 - mae: 1.5256\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2983 - mae: 1.5525\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4090 - mae: 1.5530\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8628 - mae: 1.4882\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 4.9478 - mae: 1.4981\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9483 - mae: 1.4761\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.0774 - mae: 1.4478\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.0474 - mae: 1.5344\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.0203 - mae: 1.4677\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9518 - mae: 1.5086\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5456 - mae: 1.4341\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6919 - mae: 1.4674\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8702 - mae: 1.5225\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8947 - mae: 1.4955\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8221 - mae: 1.4531\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6181 - mae: 1.4505\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6529 - mae: 1.4446\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5853 - mae: 1.5081\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7345 - mae: 1.4673\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3049 - mae: 1.4070\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5313 - mae: 1.4354\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3957 - mae: 1.4176\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2255 - mae: 1.3829\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4340 - mae: 1.3733\n",
      "processing fold #  1\n",
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 2s 5ms/sample - loss: 225.7807 - mae: 11.1982\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 32.6994 - mae: 3.6878\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 22.4487 - mae: 3.0818\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 17.8668 - mae: 2.7168\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 14.6696 - mae: 2.4986\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 14.4497 - mae: 2.4351\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.3229 - mae: 2.3492\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 12.4852 - mae: 2.2875\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.2400 - mae: 2.2234\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.5812 - mae: 2.1386\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.6650 - mae: 2.1846\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.9750 - mae: 2.1522\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.3904 - mae: 2.1357\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 10.4591 - mae: 2.1332\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.9502 - mae: 2.0341\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.2498 - mae: 2.1001\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.7283 - mae: 2.0542\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 9.7762 - mae: 1.9770\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 9.1594 - mae: 2.0199\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.3910 - mae: 1.9859\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.0457 - mae: 1.9953\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.9358 - mae: 1.9719\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.7785 - mae: 1.9669\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.0282 - mae: 1.9312\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.5480 - mae: 1.9070\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.1997 - mae: 1.8841\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.1070 - mae: 1.8352\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.5254 - mae: 1.8812\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.4914 - mae: 1.8640\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8335 - mae: 1.7680\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.3501 - mae: 1.8568\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.2934 - mae: 1.8747\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.0078 - mae: 1.8449\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8278 - mae: 1.8255\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.4493 - mae: 1.8814\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2808 - mae: 1.8287\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 7.3625 - mae: 1.7775\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 7.5263 - mae: 1.8092\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 7.1111 - mae: 1.7725 0s - loss: 2.4457\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.1021 - mae: 1.8020\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.4677 - mae: 1.7108\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.6867 - mae: 1.7332\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.8198 - mae: 1.6979\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.5070 - mae: 1.7173\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.8976 - mae: 1.6770\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.7321 - mae: 1.6706\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.1722 - mae: 1.6770\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.3254 - mae: 1.5893\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.3947 - mae: 1.7044\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4894 - mae: 1.6503\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.9742 - mae: 1.6164\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.5320 - mae: 1.6821\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8948 - mae: 1.6212\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 6.2507 - mae: 1.6574\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 6.1820 - mae: 1.5943\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7321 - mae: 1.5707\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.5044 - mae: 1.6375\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7145 - mae: 1.5853\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3984 - mae: 1.5633\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4891 - mae: 1.5365\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3613 - mae: 1.5683\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1828 - mae: 1.5451\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.5481 - mae: 1.4930\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1863 - mae: 1.5084\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9986 - mae: 1.5320\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9102 - mae: 1.5302\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.0626 - mae: 1.4291\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2116 - mae: 1.4291\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8013 - mae: 1.5062\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.0530 - mae: 1.5202\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2001 - mae: 1.4600\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6589 - mae: 1.4910\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8877 - mae: 1.4568\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4464 - mae: 1.4611\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4389 - mae: 1.4475\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4326 - mae: 1.4131\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2506 - mae: 1.4122\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.0297 - mae: 1.3634\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3237 - mae: 1.3847\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2832 - mae: 1.4059\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 4.1936 - mae: 1.3904\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1468 - mae: 1.3543\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1406 - mae: 1.3802\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.6813 - mae: 1.3400\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.6516 - mae: 1.3526\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.8206 - mae: 1.3618\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.7400 - mae: 1.3554\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.6513 - mae: 1.3025\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5826 - mae: 1.3234\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.4172 - mae: 1.2899\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.7749 - mae: 1.2847\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.7958 - mae: 1.3441\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.3316 - mae: 1.2996\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.3281 - mae: 1.2728\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.4452 - mae: 1.3343\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.4685 - mae: 1.2972\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5836 - mae: 1.2859\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.3116 - mae: 1.2515\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.4106 - mae: 1.2342\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5440 - mae: 1.2569\n",
      "processing fold #  2\n",
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 2s 5ms/sample - loss: 205.2351 - mae: 10.9598\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 28.5656 - mae: 3.5472\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 19.6314 - mae: 2.9547\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 15.6145 - mae: 2.6747\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 13.7508 - mae: 2.5214\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.1424 - mae: 2.3809\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.5677 - mae: 2.3436\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.1665 - mae: 2.2929\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.0998 - mae: 2.2552\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.0249 - mae: 2.1730\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.3891 - mae: 2.1198\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.8761 - mae: 2.0427\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.6514 - mae: 1.9871\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.9712 - mae: 1.9987\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8528 - mae: 1.9354\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8194 - mae: 1.9519\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.7462 - mae: 1.9485\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.8334 - mae: 1.9127\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.3129 - mae: 1.8909\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2207 - mae: 1.8617\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.1594 - mae: 1.8209\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.1507 - mae: 1.8656\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.5427 - mae: 1.7788\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.6646 - mae: 1.7735\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4636 - mae: 1.7743\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.5887 - mae: 1.7779\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.2312 - mae: 1.7029\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.0187 - mae: 1.7585\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.9251 - mae: 1.7382\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8091 - mae: 1.6777\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.9410 - mae: 1.7457\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.2582 - mae: 1.6984\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7724 - mae: 1.6708\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8678 - mae: 1.6999\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8470 - mae: 1.6769\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7656 - mae: 1.6792\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.9617 - mae: 1.6457\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3420 - mae: 1.6209\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4327 - mae: 1.6397\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6311 - mae: 1.6323\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4501 - mae: 1.6043\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3675 - mae: 1.6516\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2090 - mae: 1.5779\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2546 - mae: 1.5742\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1474 - mae: 1.5919\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9930 - mae: 1.6170\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1138 - mae: 1.5668\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9583 - mae: 1.5635\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8209 - mae: 1.5173\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2718 - mae: 1.4853\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.0361 - mae: 1.5705\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7794 - mae: 1.5319\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7097 - mae: 1.5295\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6008 - mae: 1.4861\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5015 - mae: 1.5240\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2752 - mae: 1.5233\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6214 - mae: 1.5472\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3357 - mae: 1.4507\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3474 - mae: 1.4699\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4657 - mae: 1.4650\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1437 - mae: 1.4318\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2808 - mae: 1.4858\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1368 - mae: 1.4327\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.0045 - mae: 1.4474\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.0353 - mae: 1.4041\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.8819 - mae: 1.3635\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.9688 - mae: 1.4138\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1182 - mae: 1.4006\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.9114 - mae: 1.4328\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1075 - mae: 1.4443\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.8268 - mae: 1.4069\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.7941 - mae: 1.3894\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.9391 - mae: 1.3976\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.7456 - mae: 1.4030\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.7683 - mae: 1.3807\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5620 - mae: 1.3526\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.4542 - mae: 1.3344\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5899 - mae: 1.3700\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.8439 - mae: 1.3624\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.6255 - mae: 1.3485\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.5162 - mae: 1.3426\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5468 - mae: 1.3296\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.5866 - mae: 1.3426\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.6113 - mae: 1.3596\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1550 - mae: 1.2655\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.2327 - mae: 1.2699\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.3323 - mae: 1.3698\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.0528 - mae: 1.2526\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1229 - mae: 1.2834\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.1587 - mae: 1.2300\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.1887 - mae: 1.2784\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 2.9040 - mae: 1.2376\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.0800 - mae: 1.2720\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1727 - mae: 1.3090\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 2.9521 - mae: 1.2525\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1105 - mae: 1.2725\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1279 - mae: 1.2634\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.1435 - mae: 1.2891\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 2.9104 - mae: 1.2290\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.0526 - mae: 1.2384\n",
      "processing fold #  3\n",
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 1s 5ms/sample - loss: 160.3246 - mae: 9.2301\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 26.2277 - mae: 3.3755\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 18.9583 - mae: 2.8846\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 16.7776 - mae: 2.6541\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 14.9431 - mae: 2.5038\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 13.6536 - mae: 2.4125\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.3432 - mae: 2.3282\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.1262 - mae: 2.2865\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 12.0015 - mae: 2.2345\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.8952 - mae: 2.2325\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 11.0636 - mae: 2.1659\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 10.8377 - mae: 2.1091\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.4076 - mae: 2.0381\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.8645 - mae: 2.0862\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.1410 - mae: 2.0391\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.1805 - mae: 2.0624\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.6817 - mae: 2.0082\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.3826 - mae: 1.9647\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 9.2745 - mae: 1.9514\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.8437 - mae: 1.9610\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 8.2504 - mae: 1.8978\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.7125 - mae: 1.9315\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.3399 - mae: 1.8996\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.3084 - mae: 1.8672\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 8.1205 - mae: 1.8618\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.7578 - mae: 1.7697\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.6746 - mae: 1.8852\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.7952 - mae: 1.7788\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.7364 - mae: 1.7937\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2793 - mae: 1.7550\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2746 - mae: 1.7951\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.2630 - mae: 1.7986\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.7437 - mae: 1.7282\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 7.1784 - mae: 1.7814\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.8140 - mae: 1.7178\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.9340 - mae: 1.7372\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.7424 - mae: 1.7631\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.6054 - mae: 1.7067\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.5043 - mae: 1.6510\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.2838 - mae: 1.6218\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.4848 - mae: 1.6871\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.2859 - mae: 1.7239\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.1347 - mae: 1.6358\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.3187 - mae: 1.7153\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.1764 - mae: 1.6739\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.8852 - mae: 1.6101\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 6.0582 - mae: 1.6573\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7774 - mae: 1.5982\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7844 - mae: 1.6000\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7387 - mae: 1.5506\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.7908 - mae: 1.6194\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8570 - mae: 1.6202\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.8888 - mae: 1.5547\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6066 - mae: 1.5476\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.5938 - mae: 1.5348\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.9311 - mae: 1.5650\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3117 - mae: 1.5033\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 5.5961 - mae: 1.5381\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1582 - mae: 1.5161\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3740 - mae: 1.4667\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.6935 - mae: 1.5674\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.4875 - mae: 1.4872\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3194 - mae: 1.5132\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1791 - mae: 1.5397\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3733 - mae: 1.4811\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2160 - mae: 1.5279\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.3451 - mae: 1.4704\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1351 - mae: 1.5370\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1592 - mae: 1.4835\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.2614 - mae: 1.4726\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1547 - mae: 1.5101\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1189 - mae: 1.4799\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7533 - mae: 1.4220\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 4.8538 - mae: 1.4099\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8723 - mae: 1.5071\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 5.1649 - mae: 1.4558\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.6284 - mae: 1.4447\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9514 - mae: 1.4410\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.9335 - mae: 1.4313\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8248 - mae: 1.3852\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7808 - mae: 1.4057\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.8487 - mae: 1.3990\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7261 - mae: 1.4412\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4075 - mae: 1.3996\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.7100 - mae: 1.4123\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5156 - mae: 1.4150\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3973 - mae: 1.3512\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.4048 - mae: 1.3969\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2192 - mae: 1.3829\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.5000 - mae: 1.3804\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.3165 - mae: 1.3794\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.0576 - mae: 1.3751\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1305 - mae: 1.3858\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.1633 - mae: 1.3488\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.7959 - mae: 1.3342\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.2174 - mae: 1.3314\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 4.3677 - mae: 1.3376\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 3.9190 - mae: 1.3251\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 3.6855 - mae: 1.3265\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 4.0819 - mae: 1.3347\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // 4\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold # ', i)\n",
    "  # prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "  # prepare the training data: data from data - k\n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [train_data[:i * num_val_samples],\n",
    "      train_data[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [train_targets[:i * num_val_samples],\n",
    "      train_targets[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  # Build the Keras Models (already commpiled)\n",
    "    model = build_model()\n",
    "  # Train the model (in silence mode, verbose = 0)\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs = num_epochs,batch_size = 1, verbose = 1)\n",
    "  # Evaluate the model on the validation data\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0251644, 2.2901309, 2.9197736, 2.2728546]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3769808"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // 4\n",
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i)\n",
    "  # prepare the validation data: data from partition # k\n",
    "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "  # prepare the training data: data from data - k\n",
    "  partial_train_data = np.concatenate(                    \n",
    "      [train_data[:i * num_val_samples],\n",
    "      train_data[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  partial_train_targets = np.concatenate(\n",
    "      [train_targets[:i * num_val_samples],\n",
    "      train_targets[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  # Build the Keras Models (already commpiled)\n",
    "  model = build_model()\n",
    "  # Train the model (in silence mode, verbose = 0)\n",
    "  history = model.fit(partial_train_data, partial_train_targets, validation_data = (val_data, val_targets), epochs = num_epochs, batch_size = 1, verbose = 1)\n",
    "  mae_history = history.history['val_mean_absolute_error']\n",
    "  all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usama Khan\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Usama Khan\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(average_mae_history) + 1 ), average_mae_history)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Validation Scores - Excluding the first 10 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1- factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/80\n",
      "404/404 [==============================] - 1s 2ms/sample - loss: 507.7095 - mae: 20.5658\n",
      "Epoch 2/80\n",
      "404/404 [==============================] - 0s 165us/sample - loss: 332.0061 - mae: 16.0385\n",
      "Epoch 3/80\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 153.6165 - mae: 9.9926\n",
      "Epoch 4/80\n",
      "404/404 [==============================] - 0s 139us/sample - loss: 64.1220 - mae: 5.9709\n",
      "Epoch 5/80\n",
      "404/404 [==============================] - 0s 163us/sample - loss: 37.4527 - mae: 4.4487\n",
      "Epoch 6/80\n",
      "404/404 [==============================] - 0s 172us/sample - loss: 27.9662 - mae: 3.7782\n",
      "Epoch 7/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 23.8936 - mae: 3.4365\n",
      "Epoch 8/80\n",
      "404/404 [==============================] - 0s 174us/sample - loss: 21.3058 - mae: 3.1868\n",
      "Epoch 9/80\n",
      "404/404 [==============================] - 0s 153us/sample - loss: 19.2153 - mae: 3.0430\n",
      "Epoch 10/80\n",
      "404/404 [==============================] - 0s 174us/sample - loss: 17.6182 - mae: 2.9046\n",
      "Epoch 11/80\n",
      "404/404 [==============================] - 0s 157us/sample - loss: 16.2690 - mae: 2.7729\n",
      "Epoch 12/80\n",
      "404/404 [==============================] - 0s 181us/sample - loss: 15.2155 - mae: 2.7072\n",
      "Epoch 13/80\n",
      "404/404 [==============================] - 0s 174us/sample - loss: 14.3477 - mae: 2.6188\n",
      "Epoch 14/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 13.4899 - mae: 2.5308\n",
      "Epoch 15/80\n",
      "404/404 [==============================] - 0s 202us/sample - loss: 12.9391 - mae: 2.4905\n",
      "Epoch 16/80\n",
      "404/404 [==============================] - 0s 193us/sample - loss: 12.3982 - mae: 2.4297\n",
      "Epoch 17/80\n",
      "404/404 [==============================] - 0s 197us/sample - loss: 12.0424 - mae: 2.4144\n",
      "Epoch 18/80\n",
      "404/404 [==============================] - 0s 208us/sample - loss: 11.6507 - mae: 2.3787\n",
      "Epoch 19/80\n",
      "404/404 [==============================] - 0s 197us/sample - loss: 11.1392 - mae: 2.3679\n",
      "Epoch 20/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 11.1739 - mae: 2.4238\n",
      "Epoch 21/80\n",
      "404/404 [==============================] - 0s 189us/sample - loss: 10.7862 - mae: 2.3025\n",
      "Epoch 22/80\n",
      "404/404 [==============================] - 0s 190us/sample - loss: 10.4854 - mae: 2.3109\n",
      "Epoch 23/80\n",
      "404/404 [==============================] - 0s 198us/sample - loss: 10.0650 - mae: 2.2729\n",
      "Epoch 24/80\n",
      "404/404 [==============================] - 0s 182us/sample - loss: 10.2367 - mae: 2.2349\n",
      "Epoch 25/80\n",
      "404/404 [==============================] - 0s 175us/sample - loss: 9.9089 - mae: 2.2623\n",
      "Epoch 26/80\n",
      "404/404 [==============================] - 0s 182us/sample - loss: 9.9246 - mae: 2.2474\n",
      "Epoch 27/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 9.7589 - mae: 2.1968\n",
      "Epoch 28/80\n",
      "404/404 [==============================] - 0s 178us/sample - loss: 9.3749 - mae: 2.1749\n",
      "Epoch 29/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 9.4610 - mae: 2.1865\n",
      "Epoch 30/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 9.3652 - mae: 2.1449\n",
      "Epoch 31/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 9.3416 - mae: 2.1239\n",
      "Epoch 32/80\n",
      "404/404 [==============================] - 0s 191us/sample - loss: 9.1190 - mae: 2.1339\n",
      "Epoch 33/80\n",
      "404/404 [==============================] - 0s 186us/sample - loss: 9.0346 - mae: 2.1358\n",
      "Epoch 34/80\n",
      "404/404 [==============================] - 0s 187us/sample - loss: 8.8606 - mae: 2.1284\n",
      "Epoch 35/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 8.7942 - mae: 2.1253\n",
      "Epoch 36/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 8.7563 - mae: 2.0997\n",
      "Epoch 37/80\n",
      "404/404 [==============================] - 0s 192us/sample - loss: 8.5936 - mae: 2.0806\n",
      "Epoch 38/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 8.4769 - mae: 2.0478\n",
      "Epoch 39/80\n",
      "404/404 [==============================] - 0s 202us/sample - loss: 8.4115 - mae: 2.0458\n",
      "Epoch 40/80\n",
      "404/404 [==============================] - 0s 191us/sample - loss: 8.3391 - mae: 2.0587\n",
      "Epoch 41/80\n",
      "404/404 [==============================] - 0s 202us/sample - loss: 8.3705 - mae: 2.0348\n",
      "Epoch 42/80\n",
      "404/404 [==============================] - 0s 201us/sample - loss: 8.2792 - mae: 2.0210\n",
      "Epoch 43/80\n",
      "404/404 [==============================] - 0s 190us/sample - loss: 8.0795 - mae: 1.9732\n",
      "Epoch 44/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 7.9609 - mae: 1.9948\n",
      "Epoch 45/80\n",
      "404/404 [==============================] - 0s 164us/sample - loss: 7.9007 - mae: 1.9968\n",
      "Epoch 46/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 8.0806 - mae: 2.0118\n",
      "Epoch 47/80\n",
      "404/404 [==============================] - 0s 178us/sample - loss: 7.9294 - mae: 1.9811\n",
      "Epoch 48/80\n",
      "404/404 [==============================] - 0s 182us/sample - loss: 7.8479 - mae: 1.9798\n",
      "Epoch 49/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 7.6910 - mae: 1.9327\n",
      "Epoch 50/80\n",
      "404/404 [==============================] - 0s 204us/sample - loss: 7.5732 - mae: 1.9704\n",
      "Epoch 51/80\n",
      "404/404 [==============================] - 0s 200us/sample - loss: 7.7158 - mae: 1.9661\n",
      "Epoch 52/80\n",
      "404/404 [==============================] - 0s 200us/sample - loss: 7.5662 - mae: 1.9474\n",
      "Epoch 53/80\n",
      "404/404 [==============================] - 0s 209us/sample - loss: 7.4982 - mae: 1.9056\n",
      "Epoch 54/80\n",
      "404/404 [==============================] - 0s 175us/sample - loss: 7.6208 - mae: 1.9673\n",
      "Epoch 55/80\n",
      "404/404 [==============================] - 0s 189us/sample - loss: 7.4616 - mae: 1.9425\n",
      "Epoch 56/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 7.3182 - mae: 1.8999\n",
      "Epoch 57/80\n",
      "404/404 [==============================] - 0s 185us/sample - loss: 7.3091 - mae: 1.9029\n",
      "Epoch 58/80\n",
      "404/404 [==============================] - 0s 182us/sample - loss: 7.2466 - mae: 1.9024\n",
      "Epoch 59/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 7.1813 - mae: 1.8988\n",
      "Epoch 60/80\n",
      "404/404 [==============================] - 0s 174us/sample - loss: 7.1477 - mae: 1.8750\n",
      "Epoch 61/80\n",
      "404/404 [==============================] - 0s 188us/sample - loss: 7.0382 - mae: 1.8466\n",
      "Epoch 62/80\n",
      "404/404 [==============================] - 0s 185us/sample - loss: 6.9701 - mae: 1.8949\n",
      "Epoch 63/80\n",
      "404/404 [==============================] - 0s 181us/sample - loss: 7.2696 - mae: 1.8927\n",
      "Epoch 64/80\n",
      "404/404 [==============================] - 0s 191us/sample - loss: 7.0267 - mae: 1.8660\n",
      "Epoch 65/80\n",
      "404/404 [==============================] - 0s 190us/sample - loss: 6.7966 - mae: 1.8238\n",
      "Epoch 66/80\n",
      "404/404 [==============================] - 0s 195us/sample - loss: 6.7577 - mae: 1.8257\n",
      "Epoch 67/80\n",
      "404/404 [==============================] - 0s 192us/sample - loss: 6.9363 - mae: 1.8749\n",
      "Epoch 68/80\n",
      "404/404 [==============================] - 0s 185us/sample - loss: 6.7340 - mae: 1.8749\n",
      "Epoch 69/80\n",
      "404/404 [==============================] - 0s 172us/sample - loss: 6.8386 - mae: 1.8387\n",
      "Epoch 70/80\n",
      "404/404 [==============================] - 0s 185us/sample - loss: 6.8218 - mae: 1.8381\n",
      "Epoch 71/80\n",
      "404/404 [==============================] - 0s 181us/sample - loss: 6.6530 - mae: 1.8313\n",
      "Epoch 72/80\n",
      "404/404 [==============================] - 0s 191us/sample - loss: 6.5796 - mae: 1.8389\n",
      "Epoch 73/80\n",
      "404/404 [==============================] - 0s 197us/sample - loss: 6.6658 - mae: 1.8463\n",
      "Epoch 74/80\n",
      "404/404 [==============================] - 0s 202us/sample - loss: 6.8086 - mae: 1.8421\n",
      "Epoch 75/80\n",
      "404/404 [==============================] - 0s 183us/sample - loss: 6.6072 - mae: 1.8135\n",
      "Epoch 76/80\n",
      "404/404 [==============================] - 0s 180us/sample - loss: 6.3268 - mae: 1.7368\n",
      "Epoch 77/80\n",
      "404/404 [==============================] - 0s 193us/sample - loss: 6.4314 - mae: 1.7596\n",
      "Epoch 78/80\n",
      "404/404 [==============================] - 0s 190us/sample - loss: 6.3007 - mae: 1.7919\n",
      "Epoch 79/80\n",
      "404/404 [==============================] - 0s 189us/sample - loss: 6.3495 - mae: 1.7871\n",
      "Epoch 80/80\n",
      "404/404 [==============================] - 0s 193us/sample - loss: 6.2452 - mae: 1.7654\n",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 83.6103 - mae: 2.6211\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "#Training on Entire Data\n",
    "model.fit(train_data, train_targets, epochs = 80, batch_size = 16, verbose = 1)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.162157544902726"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_15_input to have shape (13,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-da71713efe54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[1;32m---> 73\u001b[1;33m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[0;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[1;32m--> 760\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1786\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2132\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(model, x)\u001b[0m\n\u001b[0;32m    357\u001b[0m   \u001b[1;31m# Validate and standardize user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m   inputs, _, _ = model._standardize_user_data(\n\u001b[1;32m--> 359\u001b[1;33m       x, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;31m# If `model._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    572\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    575\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_15_input to have shape (13,) but got array with shape (1,)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
